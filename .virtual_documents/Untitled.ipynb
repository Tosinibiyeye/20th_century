


import pandas as pd 
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re


# Download English module
!python -m spacy download en_core_web_sm


# Load spacy English module

NER = spacy.load("en_core_web_sm")






with open('20th_century_Wiki.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', '')


text = NER(data)


# Visualize identified entities

displacy.render(text, style = "ent", jupyter = True)


df_sentences = [] # empty shell to store results

# Loop through sentences, get countries list for each sentence
for sent in text.sents:
    entity_list = [ent.text for ent in sent.ents]
    df_sentences.append({"sentence": sent, "countriess": entity_list})
    
df_sentences = pd.DataFrame(df_sentences)


df_sentences





# Import characters

Countries_df = pd.read_csv("countries_list_20th_century_1.5.csv", index_col = 0)


Countries_df.head()





# Function to filter out entities not of interest

def filter_entity(ent_list, Countries_df):
    return [ent for ent in ent_list 
            if ent in list(Countries_df['Countries_alias'])]


df_sentences['character_entity'] = df_sentences['entity'].apply(lambda x: filter_entity(x, Countries_df))


# Check

filter_entity(["Alice", "CF", "2"], Countries_df)












